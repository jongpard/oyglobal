import asyncio
import csv
import os
from datetime import datetime, timezone, timedelta

from oy_global import scrape_oliveyoung_global


KST = timezone(timedelta(hours=9))
DATA_DIR = "data"


def _now_kst_date() -> str:
    return datetime.now(KST).strftime("%Y-%m-%d")


def _ensure_dir(path: str) -> None:
    if not os.path.isdir(path):
        os.makedirs(path, exist_ok=True)


def _save_csv(rows, out_path: str) -> None:
    _ensure_dir(os.path.dirname(out_path))
    headers = [
        "date_kst",
        "rank",
        "brand",
        "product_name",
        "price_current_usd",
        "price_original_usd",
        "discount_rate_pct",
        "value_price_usd",
        "has_value_price",
        "product_url",
        "image_url",
    ]
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        for r in rows:
            writer.writerow({k: r.get(k, "") for k in headers})


def _pretty_title(brand: str, name: str) -> str:
    b = (brand or "").strip()
    n = (name or "").strip()
    if not b:
        return n
    # ì œí’ˆëª…ì´ ë¸Œëœë“œë¡œ ì‹œì‘í•˜ë©´ ì¤‘ë³µ ë°©ì§€
    if n.lower().startswith(b.lower()):
        return n
    return f"{b} {n}"


def _format_top10_for_slack(rows) -> str:
    lines = []
    title = f"ì˜¬ë¦¬ë¸Œì˜ ê¸€ë¡œë²Œ ì „ì²´ ë­í‚¹ ({_now_kst_date()} KST)"
    lines.append(title)
    lines.append("TOP 10")
    for r in rows[:10]:
        name = _pretty_title(r["brand"], r["product_name"])
        url = r["product_url"]
        cur = r.get("price_current_usd")
        orig = r.get("price_original_usd")
        disc = r.get("discount_rate_pct")
        # ìŠ¬ë™ ë§í¬ í¬ë§·
        link = f"<{url}|{name}>"
        # ê°€ê²© ë¼ì¸
        price_bits = []
        if cur:
            price_bits.append(f"US${cur}")
        if orig:
            price_bits.append(f"(ì •ê°€ US${orig})")
        if disc is not None and disc != "":
            price_bits.append(f"(â†“{disc}%)")
        price_str = " ".join(price_bits) if price_bits else ""
        lines.append(f"{r['rank']}. {link} â€“ {price_str}")
    lines.append("")  # ë ì¤„
    return "\n".join(lines)


async def run():
    print("ğŸ” ì˜¬ë¦¬ë¸Œì˜ ê¸€ë¡œë²Œëª° ë² ìŠ¤íŠ¸ ì…€ëŸ¬ ìˆ˜ì§‘ ì‹œì‘")
    items = await scrape_oliveyoung_global()
    # rank ë³´ì •(1~100)
    for idx, it in enumerate(items[:100], start=1):
        it["rank"] = idx
        it["date_kst"] = _now_kst_date()

    out_path = os.path.join(DATA_DIR, f"oliveyoung_global_{_now_kst_date()}.csv")
    _save_csv(items[:100], out_path)
    print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {out_path}")

    # ìŠ¬ë™ ì•Œë¦¼(ì˜µì…˜)
    webhook = os.getenv("SLACK_WEBHOOK_URL", "").strip()
    if webhook:
        import json, urllib.request

        payload = {"text": _format_top10_for_slack(items)}
        req = urllib.request.Request(
            webhook,
            data=json.dumps(payload).encode("utf-8"),
            headers={"Content-Type": "application/json"},
        )
        try:
            with urllib.request.urlopen(req, timeout=10) as resp:
                print(f"âœ… Sent Slack message. status={resp.status}")
        except Exception as e:
            print(f"âš ï¸ Slack ì „ì†¡ ì‹¤íŒ¨: {e}")
    else:
        print("â„¹ï¸ SLACK_WEBHOOK_URL ë¯¸ì„¤ì • â€” ìŠ¬ë™ ì „ì†¡ ìƒëµ")


if __name__ == "__main__":
    asyncio.run(run())
