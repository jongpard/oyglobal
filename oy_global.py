# -*- coding: utf-8 -*-
from __future__ import annotations

import asyncio
import re
from datetime import datetime, timedelta, timezone
from typing import Dict, List

from playwright.async_api import async_playwright, Page, Locator

BASE_URL = "https://global.oliveyoung.com/"

# ì•„ì£¼ ì¢ê²Œ: Top Orders(=ë² ìŠ¤íŠ¸/ì¸ê¸°) ì„¹ì…˜ì—ì„œë§Œ a[href*=product/detail] ì¶”ì¶œ
SEL_PRODUCT_ANCHOR = "a[href*='product/detail']"

# KST
KST = timezone(timedelta(hours=9))

def _now_kst_date() -> str:
    return datetime.now(KST).strftime("%Y-%m-%d")

def _to_float(s: str) -> float:
    try:
        return float(s)
    except Exception:
        return 0.0

def _split_brand_and_product(anchor_text: str) -> (str, str):
    """
    ì¹´ë“œ ì•µì»¤ í…ìŠ¤íŠ¸ëŠ” ë³´í†µ
      1í–‰: ë¸Œëœë“œ
      2í–‰: ì œí’ˆëª…(ë¸Œëœë“œ í¬í•¨ì¼ ë•Œë„ ìˆì–´ì„œ ì •ê·œì‹ìœ¼ë¡œ ì• ë¸Œëœë“œ ì œê±°)
    í˜•íƒœë¼ ì¤„ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ë’¤, ì²« ì¤„=ë¸Œëœë“œ, ë‚˜ë¨¸ì§€ í•©ì¹œ ë’¤
    ë§¨ ì• ë¸Œëœë“œëª… ë°˜ë³µë˜ë©´ ì œê±°í•©ë‹ˆë‹¤.
    """
    lines = [ln.strip() for ln in anchor_text.splitlines() if ln.strip()]
    if not lines:
        return "", ""

    brand = lines[0]
    rest = " ".join(lines[1:]).strip()

    if not rest:
        # ë¼ì¸ì´ í•˜ë‚˜ë¿ì´ë©´, ë¸Œëœë“œê°€ ì•µì»¤ ì „ì²´ë¥¼ ì°¨ì§€í•˜ëŠ” ì¼€ì´ìŠ¤.
        # ì´ëŸ° ê²½ìš°ëŠ” ë³´í†µ ê·¸ ì•„ë˜ ë‹¤ë¥¸ ë…¸ë“œì— ì œí’ˆëª…ì´ ë¶„ë¦¬ë¼ ìˆì§€ ì•Šì•„ì„œ
        # ì•µì»¤ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë¸Œëœë“œ ë°˜ë³µ ì œê±°ë¥¼ ì‹œë„
        txt = " ".join(lines)
        # "BRAND BRAND something" ê°™ì€ íŒ¨í„´ ì •ë¦¬
        if txt.lower().startswith((brand + " ").lower()):
            rest = txt[len(brand):].strip()
        else:
            rest = txt

    # ì œí’ˆëª…ì— ë¸Œëœë“œê°€ í•œ ë²ˆ ë” ì•ì— ë¶™ì–´ ìˆìœ¼ë©´ ì œê±°
    pattern = re.compile(rf"^{re.escape(brand)}\s+", re.IGNORECASE)
    product = pattern.sub("", rest).strip()

    return brand, product

_price_cur_re = re.compile(r"US\$\s*([0-9]+(?:\.[0-9]+)?)")
_price_val_re = re.compile(r"(?:ì •ê°€|Value)\s*[: ]?\s*US\$\s*([0-9]+(?:\.[0-9]+)?)", re.IGNORECASE)

def _parse_prices(text: str) -> Dict[str, float | int]:
    """
    ì¹´ë“œ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í˜„ì¬ê°€/ì •ê°€(=value) ì¶”ì¶œ.
    - í˜„ì¬ê°€: í…ìŠ¤íŠ¸ ìƒ ì²« ë²ˆì§¸ US$ ìˆ«ì
    - ì •ê°€(value): 'ì •ê°€' ë˜ëŠ” 'Value' ìˆ˜ì‹ì–´ê°€ ë¶™ì€ US$ ìˆ«ì (ì—†ìœ¼ë©´ 0)
    í• ì¸ìœ¨ì€ ë‘˜ ë‹¤ ìˆì„ ë•Œ ê³„ì‚°
    """
    cur = 0.0
    val = 0.0

    m_cur = _price_cur_re.search(text)
    if m_cur:
        cur = _to_float(m_cur.group(1))

    m_val = _price_val_re.search(text)
    if m_val:
        val = _to_float(m_val.group(1))

    disc = 0.0
    if val > 0 and cur > 0 and val >= cur:
        disc = round((val - cur) / val * 100, 2)

    return dict(
        price_current_usd=cur,
        price_original_usd=val,   # 'ì •ê°€/Value'ë¥¼ ì›ê°€ë¡œ ì‚¬ìš©
        discount_rate_pct=disc,
        value_price_usd=val,
        has_value_price=1 if val > 0 else 0,
    )

async def _get_section_locator(page: Page, title_regex: re.Pattern) -> Locator:
    """
    í˜ì´ì§€ì—ì„œ 'Top Orders'/'Best Sellers' ë¥˜ íƒ€ì´í‹€(h2/h3)ì„ ì°¾ì•„
    ê°€ì¥ ê°€ê¹Œìš´ ì„¹ì…˜ ì»¨í…Œì´ë„ˆ(ancestor section/div)ë¥¼ ë°˜í™˜
    """
    heading = page.locator("h2, h3").filter(has_text=title_regex).first
    await heading.wait_for(state="visible", timeout=30000)
    # ì„¹ì…˜ ë˜ëŠ” ê°€ì¥ ê°€ê¹Œìš´ divë¡œ í•œì •
    section = heading.locator("xpath=ancestor::*[self::section or self::div][1]")
    return section

async def _autoscroll_collect(section: Locator, need: int = 100) -> List[Locator]:
    """
    ì„¹ì…˜ ì•ˆì—ì„œ ìƒí’ˆ ì¹´ë“œ a[href*=product/detail]ë¥¼ ëª¨ìœ¼ë©´ì„œ ìë™ ìŠ¤í¬ë¡¤.
    needê°œ ì´ìƒ ë˜ëŠ” ë” ì´ìƒ ëŠ˜ì–´ë‚˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œ.
    """
    seen = set()
    anchors: List[Locator] = []

    # ì„¹ì…˜ ë§¨ ìœ„ë¶€í„°
    await section.scroll_into_view_if_needed()

    idle_rounds = 0
    while True:
        await asyncio.sleep(0.3)
        new_found = 0

        # í˜„ì¬ ë³´ì´ëŠ” ì•µì»¤ë“¤
        batch = section.locator(SEL_PRODUCT_ANCHOR)
        count = await batch.count()
        for i in range(count):
            a = batch.nth(i)
            href = await a.get_attribute("href") or ""
            if not href:
                continue
            if href in seen:
                continue

            # ì¹´ë“œ ë£¨íŠ¸(ê°€ì¥ ê°€ê¹Œìš´ ìƒí’ˆ ì¹´ë“œ) ì¡ê³ , í™”ë©´ì— ìŠ¤í¬ë¡¤
            card = a.locator("xpath=ancestor::*[self::li or self::div][1]")
            try:
                await card.scroll_into_view_if_needed()
            except Exception:
                pass

            anchors.append(a)
            seen.add(href)
            new_found += 1

        if len(anchors) >= need:
            break

        if new_found == 0:
            idle_rounds += 1
        else:
            idle_rounds = 0

        # ë” ì´ìƒ ëŠ˜ì§€ ì•Šìœ¼ë©´ íƒˆì¶œ
        if idle_rounds >= 5:
            break

        # ì•„ë˜ë¡œ ì¡°ê¸ˆ ë” ìŠ¤í¬ë¡¤ ìœ ë„
        try:
            await section.evaluate("(el) => el.scrollBy(0, el.clientHeight)")
        except Exception:
            break

    return anchors[:need]

async def _extract_item_from_anchor(a: Locator) -> Dict:
    """
    ë‹¨ì¼ ì•µì»¤ì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (ë¸Œëœë“œ/ì œí’ˆëª…/ê°€ê²©/URL/ì´ë¯¸ì§€)
    """
    href = await a.get_attribute("href") or ""
    product_url = href if href.startswith("http") else (BASE_URL.rstrip("/") + "/" + href.lstrip("/"))

    # ì¹´ë“œ ì „ì²´ í…ìŠ¤íŠ¸(ê°€ê²© í¬í•¨)ë¥¼ ì–»ê¸° ìœ„í•´ ì¹´ë“œ ë£¨íŠ¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
    card = a.locator("xpath=ancestor::*[self::li or self::div][1]")
    card_text = await card.inner_text()

    # ì•µì»¤ í…ìŠ¤íŠ¸ë¡œ ë¸Œëœë“œ/ìƒí’ˆëª… ë¶„ë¦¬
    anchor_text = await a.inner_text()
    brand, product = _split_brand_and_product(anchor_text)

    # ì´ë¯¸ì§€
    img = ""
    try:
        img = await a.locator("img").first.get_attribute("src") or ""
    except Exception:
        pass

    prices = _parse_prices(card_text)

    return dict(
        brand=brand,
        product_name=product or brand,  # í˜¹ì‹œ ëª» ë½‘ì•„ë„ ë¹„ì–´ìˆì§€ ì•Šê²Œ
        price_current_usd=prices["price_current_usd"],
        price_original_usd=prices["price_original_usd"],
        discount_rate_pct=prices["discount_rate_pct"],
        value_price_usd=prices["value_price_usd"],
        has_value_price=bool(prices["has_value_price"]),
        product_url=product_url,
        image_url=img,
    )

async def scrape_oliveyoung_global() -> List[Dict]:
    async with async_playwright() as pw:
        browser = await pw.chromium.launch(headless=True)
        page = await browser.new_page(viewport={"width": 1366, "height": 900})
        await page.goto(BASE_URL, wait_until="domcontentloaded")

        # Top Orders / Best Sellers ë“±ìœ¼ë¡œ ë³´ì´ëŠ” ì„¹ì…˜ì„ í­ë„“ê²Œ ë§¤ì¹­
        title_re = re.compile(r"(Top\s*Orders|Best\s*Sellers|TOP\s*100|TOP\s*50|TOP\s*10)", re.I)
        section = await _get_section_locator(page, title_re)

        # ì„¹ì…˜ ì•ˆì—ì„œ ì œí’ˆ ì•µì»¤ ëŒ€ê¸° â†’ ìˆ˜ì§‘
        await section.locator(SEL_PRODUCT_ANCHOR).first.wait_for(state="visible", timeout=30000)
        anchors = await _autoscroll_collect(section, need=100)

        items: List[Dict] = []
        for a in anchors:
            try:
                data = await _extract_item_from_anchor(a)
                items.append(data)
            except Exception:
                continue

        await browser.close()

    # ë­í¬/ë‚ ì§œ ë¶€ì—¬
    date_kst = _now_kst_date()
    for i, it in enumerate(items, start=1):
        it["date_kst"] = date_kst
        it["rank"] = i

    return items


# ----------------- CSV ì €ì¥ ìœ í‹¸ -----------------
import csv
from pathlib import Path

CSV_HEADER = [
    "date_kst",
    "rank",
    "brand",
    "product_name",
    "price_current_usd",
    "price_original_usd",
    "discount_rate_pct",
    "value_price_usd",
    "has_value_price",
    "product_url",
    "image_url",
]

def save_csv(items: List[Dict], path: str) -> None:
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=CSV_HEADER)
        w.writeheader()
        for it in items:
            row = {k: it.get(k, "") for k in CSV_HEADER}
            w.writerow(row)


# ----------------- ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ -----------------
if __name__ == "__main__":
    import os
    out = f"data/oliveyoung_global_{_now_kst_date()}.csv"
    print("ğŸ” ì˜¬ë¦¬ë¸Œì˜ ê¸€ë¡œë²Œëª° ë² ìŠ¤íŠ¸ ì…€ëŸ¬ ìˆ˜ì§‘ ì‹œì‘")
    items = asyncio.run(scrape_oliveyoung_global())  # List[dict]
    save_csv(items, out)
    print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {out}")
    # ìŠ¬ë™ì€ ë³„ë„ stepì—ì„œ ì²˜ë¦¬
